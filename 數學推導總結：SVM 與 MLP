#SVM 與 MLP

## 1. SVM (Support Vector Machine) 的訓練過程

SVM 的核心目標是找到一個**最大邊界超平面**，將不同類別的數據點分開。這是一個**二次規劃 (Quadratic Programming)** 問題。

### 找出最佳的 $\mathbf{W}$ 和 $b$ 的數學推導

#### A. 原始優化問題 (Primal Problem)

對於線性可分 (Hard Margin) 的數據，目標是最大化邊界 $\frac{2}{\|\mathbf{w}\|}$，等價於最小化 $\frac{1}{2}\|\mathbf{w}\|^2$。

**目標函數 (最小化):**
![目標函數 (最小化)](https://latex.codecogs.com/png.latex?%5Cmin_%7B%5Cmathbf%7Bw%7D%2C%20b%7D%20%5Cquad%20%5Cfrac%7B1%7D%7B2%7D%7C%7C%5Cmathbf%7Bw%7D%7C%7C%5E2)

**約束條件:**
$$\text{s.t.} \quad y^{(i)} (\mathbf{w}^T \mathbf{x}^{(i)} + b) \ge 1 \quad \text{for } i=1, \dots, m$$

其中 $y^{(i)} \in \{-1, 1\}$ 是類別標籤。

#### B. 轉換為對偶問題 (Dual Problem)

**拉格朗日函數 (Lagrangian):**
![拉格朗日函數 (Lagrangian)](https://latex.codecogs.com/png.latex?%5Cmathcal%7BL%7D(%5Cmathbf%7Bw%7D%2C%20b%2C%20%5Cboldsymbol%7B%5Calpha%7D)%20%3D%20%5Cfrac%7B1%7D%7B2%7D%7C%7C%5Cmathbf%7Bw%7D%7C%7C%5E2%20%2B%20%5Csum_%7Bi=1%7D%5E%7Bm%7D%20%5Calpha_i%20%5Cleft%5B%201%20-%20y%5E%7B(i)%7D%20(%5Cmathbf%7Bw%7D%5E%7BT%7D%20%5Cmathbf%7Bx%7D%5E%7B(i)%7D%20%2B%20b)%20%5Cright%5D)

**求解 $\mathbf{w}$ 的條件 (最佳權重的形式):**
![求解 w 的條件 (最佳權重的形式)](https://latex.codecogs.com/png.latex?%5Cfrac%7B%5Cpartial%20%5Cmathcal%7BL%7D%7D%7B%5Cpartial%20%5Cmathbf%7Bw%7D%7D%20%3D%200%20%5Cimplies%20%5Cmathbf%7Bw%7D%5E%7B*%7D%20%3D%20%5Csum_%7Bi=1%7D%5E%7Bm%7D%20%5Calpha_i%20y%5E%7B(i)%7D%20%5Cmathbf%7Bx%7D%5E%7B(i)%7D)

**求解 $b$ 的條件 ($\boldsymbol{\alpha}$ 的約束):**
![求解 b 的條件 (alpha 的約束)](https://latex.codecogs.com/png.latex?%5Cfrac%7B%5Cpartial%20%5Cmathcal%7BL%7D%7D%7B%5Cpartial%20b%7D%20%3D%200%20%5Cimplies%20%5Csum_%7Bi=1%7D%5E%7Bm%7D%20%5Calpha_i%20y%5E%7B(i)%7D%20%3D%200)

**對偶目標函數 (Dual Objective Function):**
![對偶目標函數 (Dual Objective Function)](https://latex.codecogs.com/png.latex?%5Cmax_%7B%5Cboldsymbol%7B%5Calpha%7D%7D%20%5Cquad%20%5Csum_%7Bi=1%7D%5E%7Bm%7D%20%5Calpha_i%20-%20%5Cfrac%7B1%7D%7B2%7D%20%5Csum_%7Bi=1%7D%5E%7Bm%7D%20%5Csum_%7Bj=1%7D%5E%7Bm%7D%20%5Calpha_i%20%5Calpha_j%20y%5E%7B(i)%7D%20y%5E%7B(j)%7D%20(%5Cmathbf%7Bx%7D%5E%7B(i)%7D%20%5Ccdot%20%5Cmathbf%7Bx%7D%5E%7B(j)%7D))

#### C. 結論

**最佳權重 $\mathbf{w}^{*}$ (最終形式):**
![最佳權重 w* (最終形式)](https://latex.codecogs.com/png.latex?%5Cmathbf%7Bw%7D%5E%7B*%7D%20%3D%20%5Csum_%7Bi=1%7D%5E%7Bm%7D%20%5Calpha_i%5E%7B*%7D%20y%5E%7B(i)%7D%20%5Cmathbf%7Bx%7D%5E%7B(i)%7D)

---

## 2. MLP (Multi-Layer Perceptron) 的訓練過程

### 找出最佳的 $\mathbf{W}$ 的數學推導

#### A. 最小化目標函數

**損失函數範例 (均方誤差 MSE):**
![損失函數範例 (均方誤差 MSE)](https://latex.codecogs.com/png.latex?J(\mathbf{W},%20b)%20%3D%20%5Cfrac%7B1%7D%7B2m%7D%20%5Csum_%7Bi=1%7D%5E%7Bm%7D%20(y%5E%7B(i)%7D%20-%20%5Chat%7By%7D%5E%7B(i)%7D)%5E2)

### B. 訓練核心流程：前向傳遞與反向傳播

#### B.1. 前向傳遞 (Forward Propagation) 流程

1.  **計算加權和 (Net Input) $\mathbf{z}^{(l)}$**
    ![計算加權和 (Net Input) z(l)](https://latex.codecogs.com/png.latex?%5Cmathbf%7Bz%7D%5E%7B(l)%7D%20%3D%20%5Cmathbf%7BW%7D%5E%7B(l)%7D%20%5Cmathbf%7Ba%7D%5E%7B(l-1)%7D%20%2B%20%5Cmathbf%7Bb%7D%5E%7B(l)%7D)

2.  **計算激活輸出 (Activation) $\mathbf{a}^{(l)}$**
    ![計算激活輸出 (Activation) a(l)](https://latex.codecogs.com/png.latex?%5Cmathbf%7Ba%7D%5E%7B(l)%7D%20%3D%20g%5E%7B(l)%7D(%5Cmathbf%7Bz%7D%5E%7B(l)%7D))

#### B.2. 梯度計算：反向傳播 (Backpropagation)

1.  **輸出層誤差 $\boldsymbol{\delta}^{(L)}$:**
    ![輸出層誤差 delta(L)](https://latex.codecogs.com/png.latex?%5Cboldsymbol%7B%5Cdelta%7D%5E%7B(L)%7D%20%3D%20%5Cfrac%7B%5Cpartial%20J%7D%7B%5Cpartial%20%5Cmathbf%7Bz%7D%5E%7B(L)%7D%7D%20%3D%20(%5Chat%7B%5Cmathbf%7By%7D%7D%20-%20%5Cmathbf%7By%7D)%20%5Codot%20g'(%5Cmathbf%7Bz%7D%5E%7B(L)%7D))

2.  **隱藏層誤差 $\boldsymbol{\delta}^{(l)}$ 的遞歸:**
    ![隱藏層誤差 delta(l) 的遞歸](https://latex.codecogs.com/png.latex?%5Cboldsymbol%7B%5Cdelta%7D%5E%7B(l)%7D%20%3D%20%5Cleft%28%20(%5Cmathbf%7BW%7D%5E%7B(l)%7D)%5E%7BT%7D%20%5Cboldsymbol%7B%5Cdelta%7D%5E%7B(l%2B1)%7D%20%5Cright%29%20%5Codot%20g'(%5Cmathbf%7Bz%7D%5E%7B(l)%7D))

3.  **權重梯度 $\frac{\partial J}{\partial \mathbf{W}^{(l)}}$:**
    ![權重梯度 dJ/dW(l)](https://latex.codecogs.com/png.latex?%5Cfrac%7B%5Cpartial%20J%7D%7B%5Cpartial%20%5Cmathbf%7BW%7D%5E%7B(l)%7D%7D%20%3D%20%5Cfrac%7B1%7D%7Bm%7D%20%5Cboldsymbol%7B%5Cdelta%7D%5E%7B(l%2B1)%7D%20(%5Cmathbf%7Ba%7D%5E%7B(l)%7D)%5E%7BT%7D)

4.  **偏置 $\mathbf{b}^{(l)}$ 的梯度:**
    ![偏置梯度 dJ/db(l)](https://latex.codecogs.com/png.latex?%5Cfrac%7B%5Cpartial%20J%7D%7B%5Cpartial%20%5Cmathbf%7Bb%7D%5E%7B(l)%7D%7D%20%3D%20%5Cfrac%7B1%7D%7Bm%7D%20%5Csum_%7Bi=1%7D%5E%7Bm%7D%20%5Cboldsymbol%7B%5Cdelta%7D%5E%7B(l%2C%20i)%7D)

#### C. 權重更新 (梯度下降)

**權重更新規則:**
![權重更新規則](https://latex.codecogs.com/png.latex?%5Cmathbf%7BW%7D%5E%7B*%7D%20%3D%20%5Cmathbf%7BW%7D%20-%20%5Ceta%20%5Ccdot%20%5Cfrac%7B%5Cpartial%20J%7D%7B%5Cpartial%20%5Cmathbf%7BW%7D%7D)

---

## 3. 程式中如何實現: $\mathbf{w}^{*} = \mathbf{w} + \Delta \mathbf{w}$

| 概念 | 數學表達式 | 程式實現 (偽代碼) |
| :--- | :--- | :--- |
| **當前權重** | $\mathbf{W}$ | `w` |
| **更新量 $\Delta \mathbf{W}$** | $-\eta \cdot \nabla J(\mathbf{w})$ | `delta_w = -learning_rate * gradient_J_w` |
| **學習率** | $\eta$ | `learning_rate` |
| **梯度** | $\nabla J(\mathbf{w})$ | `gradient_J_w` |
| **更新步驟** | $\mathbf{w}^{*} = \mathbf{w} - \eta \frac{\partial J}{\partial \mathbf{W}}$ | `w = w + delta_w` |

**程式碼範例 (Python/NumPy 概念):**
```python
# 1. 計算梯度 (通過反向傳播)
gradient_J_w = calculate_gradient(data, w)
# 2. 設定學習率
learning_rate = 0.01
# 3. 計算更新量 (Delta W)
delta_w = -learning_rate * gradient_J_w
# 4. 更新權重 (W* = W + Delta W)
w = w + delta_w
# 此時的 w 即為下一輪的 w*
